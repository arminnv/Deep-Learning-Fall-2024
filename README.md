# Deep Learning
This repository contains the coursework materials for the graduate course "Deep Learning", taught by Dr. Emad Fatemizadeh.

## Repository Structure

- `HW1/`: Introducation to Machine Learning
- `HW2/`: Optimization (incomplete due to TOEFL exam)
- `HW3/`: CNN Architectures, Computer Vision, and Transfer Learning
- `HW4/`: Time Series, NLP, LSTM, Attention, and LLMs
- `HW5/`: Deep Generative Models
- `Project/`: Real-Time Object Recognition

## Syllabus

1. Introductions
   - An Introduction to Machine Learning Concepts, importance, applications, and examples.
2. Rapid Survey
   - Essential Mathematics for Machine Learning, Linear Algebra and Random Variables
3. Shallow and Deep Neural networks as classifier and function approximator
   - Single layer perceptron (SLP), multilayer perceptron (MLP), error back propagation (EBP) algorithm, most important theorems.
4. Regularization, Normalization, and Optimization
   - With emphasis on stochastic gradient descent (SGD) and its variations
5. Recurrent Neural Networks
   - RNN, LSTM, GRU, Transformers, applications in natural language and signal/image processing.
6. Unsupervised Learning
   - Auto Encoder (AE), Variational Auto Encoder (VAE), Conditional Variational Auto Encoder (CVAE)
7. Adversarial learning
   - Generative Adversarial Networks (GAN) and Conditional GAN (CGAN), mathematical foundation, architecture, applications, and most important networks (GAN, DCGAN, CycleGAN, WGAN, and state of art networks)
8. Generative Models (Diffusion)
    
For more details, please refer to the project report in the `Project/` directory.
